{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhWV8oes-wKR"
   },
   "source": [
    "# COURSE: A deep understanding of deep learning\n",
    "## SECTION: Data matrices and loaders\n",
    "### LECTURE: Anatomy of a torch dataset and dataloader\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com\n",
    "##### COURSE URL: udemy.com/course/deeplearning_x/?couponCode=202401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YeuAheYyhdZw"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader,TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFv_cmvApLb0"
   },
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "aykKFgznOako"
   },
   "outputs": [],
   "source": [
    "# create some data in numpy\n",
    "\n",
    "nObservations = 100\n",
    "nFeatures = 20\n",
    "\n",
    "data = np.random.randn(nObservations,nFeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Y_tZ1ymVp0Sf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy data:\n",
      "<class 'numpy.ndarray'>\n",
      "(100, 20)\n",
      "float64\n",
      " \n",
      "Tensor data:\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([100, 20])\n",
      "torch.float64\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Convert to pytorch tensor\n",
    "dataT = torch.tensor( data ) \n",
    "\n",
    "# print out some information\n",
    "print('Numpy data:')\n",
    "print(type(data))\n",
    "print(data.shape) # numpy -> .shape\n",
    "print(data.dtype)\n",
    "print(' ')\n",
    "\n",
    "print('Tensor data:')\n",
    "print(type(dataT))\n",
    "print(dataT.size()) # torch -> .size()\n",
    "print(dataT.dtype)\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WlSTQeZ2nDDR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Sometimes you need to convert data types\n",
    "\n",
    "dataT2 = torch.tensor( data ).float()\n",
    "print(dataT2.dtype)\n",
    "\n",
    "# \"long\" is for ints\n",
    "dataT3 = torch.tensor( data ).long()\n",
    "print(dataT3.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "u5fGd4h8mI8a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0703,  0.8150, -0.6866,  ..., -0.6780, -0.8070,  1.0024],\n",
       "        [-0.1242, -0.7106,  1.3548,  ...,  1.4212,  0.0339,  0.6934],\n",
       "        [ 0.7226, -1.6978,  1.9232,  ...,  0.0142, -0.0337, -0.4619],\n",
       "        ...,\n",
       "        [ 0.4619, -1.0195, -0.4391,  ...,  0.8968, -0.0406, -0.0108],\n",
       "        [-0.8427,  0.3342,  0.6429,  ..., -2.5008, -0.1848, -0.1074],\n",
       "        [-0.0156,  0.7192, -0.1999,  ..., -0.0840, -1.7803,  0.2918]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert tensor into PyTorch Datasets\n",
    "\n",
    "# dataset = TensorDataset(data) # not a tensor!\n",
    "dataset = TensorDataset(dataT)\n",
    "\n",
    "# dataset is a two-element tuple comprising data,labels\n",
    "dataset.tensors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wpvxvxBloej3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 20])\n",
      "torch.Size([100, 1])\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "# Let's try again with labels\n",
    "labels = torch.ceil(torch.linspace(.01,4,nObservations))\n",
    "\n",
    "# transform to an actual matrix (column vector)\n",
    "labels = labels.reshape(( len(labels),1 ))\n",
    "# print( labels )\n",
    "\n",
    "# now make another dataset\n",
    "dataset = TensorDataset(dataT,labels)\n",
    "print( dataset.tensors[0].size() )\n",
    "print( dataset.tensors[1].size() )\n",
    "\n",
    "# for comparison\n",
    "print( np.shape(np.random.randint(5,size=nObservations)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJ-JsNQGpIKT"
   },
   "source": [
    "# DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5_kahYcanxBg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 20])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataloader object\n",
    "batchsize = 25\n",
    "dataloader = DataLoader(dataset,batch_size=batchsize)#,shuffle=True,drop_last=True)\n",
    "\n",
    "dataloader.dataset.tensors[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xu7BF_OTqDj0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH INFO:\n",
      "torch.Size([25, 20])\n",
      "torch.Size([25, 1])\n",
      " \n",
      "BATCH INFO:\n",
      "torch.Size([25, 20])\n",
      "torch.Size([25, 1])\n",
      " \n",
      "BATCH INFO:\n",
      "torch.Size([25, 20])\n",
      "torch.Size([25, 1])\n",
      " \n",
      "BATCH INFO:\n",
      "torch.Size([25, 20])\n",
      "torch.Size([25, 1])\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# sizes of each batch\n",
    "for dat,labs in dataloader:\n",
    "  print('BATCH INFO:')\n",
    "  print(dat.size())\n",
    "  print(labs.size())\n",
    "  print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "oLkY18PZq-G3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "         1., 1., 1., 1., 1., 1., 1.]])\n",
      " \n",
      "tensor([[2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
      "         2., 2., 2., 2., 2., 2., 2.]])\n",
      " \n",
      "tensor([[3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.,\n",
      "         3., 3., 3., 3., 3., 3., 3.]])\n",
      " \n",
      "tensor([[4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.,\n",
      "         4., 4., 4., 4., 4., 4., 4.]])\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# inspect the labels\n",
    "for dat,labs in dataloader:\n",
    "  print(labs.T)\n",
    "  print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zyeJ6mjjre6p"
   },
   "outputs": [],
   "source": [
    "# try again with shuffling (shuffling happens during iterations)\n",
    "# dataloader = DataLoader(dataset,batch_size=batchsize,shuffle=True)\n",
    "\n",
    "for dat,labs in dataloader:\n",
    "  print(labs.T)\n",
    "  print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S236TLLury42"
   },
   "outputs": [],
   "source": [
    "# To get only one batch (e.g., for testing)\n",
    "\n",
    "dat,labs = next(iter(dataloader))\n",
    "\n",
    "labs"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMDTrf0kN4swdushiJqB9Kn",
   "collapsed_sections": [],
   "name": "DUDL_data_datasetLoader.ipynb",
   "provenance": [
    {
     "file_id": "1t1AgKE-GpPPUcjGZyTF_Ie1Q9XWA3xn-",
     "timestamp": 1618172332728
    },
    {
     "file_id": "1qKgZ8kVcqNgwtBzHbWq5yJH_HqI6DxWW",
     "timestamp": 1617803880910
    },
    {
     "file_id": "15cpyHkJ435B4MqbyGjAH1poN4nCy_DE4",
     "timestamp": 1617737766196
    },
    {
     "file_id": "1OLuWuaFu0hcFgkQ2hh5BqbRuqUZD7XcQ",
     "timestamp": 1617734878578
    },
    {
     "file_id": "1XvzVGJPTJifVh8OpZVB7ykLxyUqYwQ1j",
     "timestamp": 1617196833019
    },
    {
     "file_id": "1bv1_y32e3KEExFKKlPfC3rpw1JxmBr8H",
     "timestamp": 1617124341706
    },
    {
     "file_id": "1GMq8u7KyHB2AE7Teyls9gK1T01OduQSn",
     "timestamp": 1616697516760
    },
    {
     "file_id": "1Ui3kyHim-e0XLgDs2mkBxVlYg7TKYtcg",
     "timestamp": 1616615469755
    },
    {
     "file_id": "1YpHocGI4rApOxIBb1ZghCU5L-hFnv4CK",
     "timestamp": 1616608248670
    }
   ]
  },
  "kernelspec": {
   "display_name": "deepunderstandingofdeeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
