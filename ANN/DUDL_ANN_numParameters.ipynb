{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhWV8oes-wKR"
   },
   "source": [
    "# COURSE: A deep understanding of deep learning\n",
    "## SECTION: ANNs\n",
    "### LECTURE: Depth vs. breadth: number of parameters\n",
    "#### TEACHER: Mike X Cohen, sincxpress.com\n",
    "##### COURSE URL: udemy.com/course/deeplearning_x/?couponCode=202401"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "j7-LiwqUMGYL"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "krQeh5wYMNla"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=2, out_features=4, bias=True)\n",
      "  (1): Linear(in_features=4, out_features=3, bias=True)\n",
      ")\n",
      " \n",
      "Sequential(\n",
      "  (0): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (1): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (2): Linear(in_features=2, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# build two models\n",
    "\n",
    "widenet = nn.Sequential(\n",
    "    nn.Linear(2,4),  # hidden layer\n",
    "    nn.Linear(4,3),  # output layer\n",
    "    )\n",
    "\n",
    "\n",
    "deepnet = nn.Sequential(\n",
    "    nn.Linear(2,2),  # hidden layer\n",
    "    nn.Linear(2,2),  # hidden layer\n",
    "    nn.Linear(2,3),  # output layer\n",
    "    )\n",
    "\n",
    "# print them out to have a look\n",
    "print(widenet)\n",
    "print(' ')\n",
    "print(deepnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rv5g3ISypDNk"
   },
   "outputs": [],
   "source": [
    "widenet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ni8L4jRgopMO"
   },
   "source": [
    "# Peeking inside the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lrKmii4Xmx-Z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('0.weight', Parameter containing:\n",
      "tensor([[-0.4073,  0.5204],\n",
      "        [-0.0964, -0.2418]], requires_grad=True))\n",
      " \n",
      "('0.bias', Parameter containing:\n",
      "tensor([ 0.0418, -0.3672], requires_grad=True))\n",
      " \n",
      "('1.weight', Parameter containing:\n",
      "tensor([[-0.5311,  0.5440],\n",
      "        [-0.0674,  0.2118]], requires_grad=True))\n",
      " \n",
      "('1.bias', Parameter containing:\n",
      "tensor([-0.1054,  0.1707], requires_grad=True))\n",
      " \n",
      "('2.weight', Parameter containing:\n",
      "tensor([[-0.3982,  0.3475],\n",
      "        [ 0.0418, -0.6077],\n",
      "        [-0.3060,  0.3595]], requires_grad=True))\n",
      " \n",
      "('2.bias', Parameter containing:\n",
      "tensor([ 0.1862,  0.4392, -0.0569], requires_grad=True))\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# check out the parameters\n",
    "for p in deepnet.named_parameters():\n",
    "  print(p)\n",
    "  print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "I811amwtouaY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7 nodes in the wide network.\n",
      "There are 7 nodes in the deep network.\n"
     ]
    }
   ],
   "source": [
    "# count the number of nodes ( = the number of biases)\n",
    "\n",
    "# named_parameters() is an iterable that returns the tuple (name,numbers)\n",
    "numNodesInWide = 0\n",
    "for p in widenet.named_parameters():\n",
    "  if 'bias' in p[0]:\n",
    "    numNodesInWide += len(p[1])\n",
    "\n",
    "numNodesInDeep = 0\n",
    "for paramName,paramVect in deepnet.named_parameters():\n",
    "  if 'bias' in paramName:\n",
    "    numNodesInDeep += len(paramVect)\n",
    "\n",
    "\n",
    "print('There are %s nodes in the wide network.' %numNodesInWide)\n",
    "print('There are %s nodes in the deep network.' %numNodesInDeep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "FVuYUMy7spW9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1573, -0.4116],\n",
      "        [ 0.5969,  0.0484],\n",
      "        [-0.5865, -0.6478],\n",
      "        [ 0.1288,  0.3376]], requires_grad=True)\n",
      " \n",
      "Parameter containing:\n",
      "tensor([ 0.6964,  0.1314, -0.3912,  0.2377], requires_grad=True)\n",
      " \n",
      "Parameter containing:\n",
      "tensor([[-0.4025, -0.4031,  0.3681,  0.2943],\n",
      "        [ 0.2176, -0.1565,  0.1542,  0.1853],\n",
      "        [-0.3412, -0.3108,  0.2622,  0.3650]], requires_grad=True)\n",
      " \n",
      "Parameter containing:\n",
      "tensor([ 0.0089, -0.4568, -0.4910], requires_grad=True)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# just the parameters\n",
    "for p in widenet.parameters():\n",
    "  print(p)\n",
    "  print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xtTwxsVhirEq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This piece has 8 parameters\n",
      "This piece has 4 parameters\n",
      "This piece has 12 parameters\n",
      "This piece has 3 parameters\n",
      "\n",
      "\n",
      "Total of 27 parameters\n"
     ]
    }
   ],
   "source": [
    "# now count the total number of trainable parameters\n",
    "nparams = 0\n",
    "for p in widenet.parameters():\n",
    "  if p.requires_grad:\n",
    "    print('This piece has %s parameters' %p.numel())\n",
    "    nparams += p.numel()\n",
    "\n",
    "print('\\n\\nTotal of %s parameters'%nparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PKr2ARdWivz8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Widenet has 27 parameters\n",
      "Deepnet has 21 parameters\n"
     ]
    }
   ],
   "source": [
    "# btw, can also use list comprehension\n",
    "\n",
    "nparams = np.sum([ p.numel() for p in widenet.parameters() if p.requires_grad ])\n",
    "print('Widenet has %s parameters'%nparams)\n",
    "\n",
    "nparams = np.sum([ p.numel() for p in deepnet.parameters() if p.requires_grad ])\n",
    "print('Deepnet has %s parameters'%nparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I9wsTcbrrYT7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_6GzhyxLUrYy"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# A nice simple way to print out the model info.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchsummary\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m summary\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidenet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m### NOTE ABOUT THE CODE IN THIS CELL:\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# torchsummary is being replaced by torchinfo.\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# If you are importing these libraries on your own (via pip), then see the following website:\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m#        https://pypi.org/project/torch-summary/\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# However, torchsummary will continue to be supported, so if the code in this cell works (meaning torchsummary is already installed), \u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# then you don't need to do anything!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/DeepUnderstandingOfDeepLearning/.venv/lib/python3.12/site-packages/torchsummary/torchsummary.py:72\u001b[39m, in \u001b[36msummary\u001b[39m\u001b[34m(model, input_size, batch_size, device)\u001b[39m\n\u001b[32m     68\u001b[39m model.apply(register_hook)\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# make a forward pass\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# remove these hooks\u001b[39;00m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m hooks:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/DeepUnderstandingOfDeepLearning/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/DeepUnderstandingOfDeepLearning/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/DeepUnderstandingOfDeepLearning/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/DeepUnderstandingOfDeepLearning/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/DeepUnderstandingOfDeepLearning/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1857\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1854\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m   1856\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1857\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1859\u001b[39m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[32m   1860\u001b[39m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[32m   1861\u001b[39m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[32m   1862\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/DeepUnderstandingOfDeepLearning/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1805\u001b[39m, in \u001b[36mModule._call_impl.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1802\u001b[39m     bw_hook = BackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[32m   1803\u001b[39m     args = bw_hook.setup_input_hook(args)\n\u001b[32m-> \u001b[39m\u001b[32m1805\u001b[39m result = \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1806\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks:\n\u001b[32m   1807\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[32m   1808\u001b[39m         *_global_forward_hooks.items(),\n\u001b[32m   1809\u001b[39m         *\u001b[38;5;28mself\u001b[39m._forward_hooks.items(),\n\u001b[32m   1810\u001b[39m     ):\n\u001b[32m   1811\u001b[39m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/DeepUnderstandingOfDeepLearning/.venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "# A nice simple way to print out the model info.\n",
    "from torchsummary import summary\n",
    "summary(widenet,(1,2))\n",
    "\n",
    "\n",
    "### NOTE ABOUT THE CODE IN THIS CELL:\n",
    "# torchsummary is being replaced by torchinfo.\n",
    "# If you are importing these libraries on your own (via pip), then see the following website:\n",
    "#        https://pypi.org/project/torch-summary/\n",
    "# However, torchsummary will continue to be supported, so if the code in this cell works (meaning torchsummary is already installed), \n",
    "# then you don't need to do anything!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KHlWL3_drYhT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNp0/OYNZqgbUCz8Xrl2dyW",
   "collapsed_sections": [],
   "name": "DUDL_ANN_numParameters.ipynb",
   "provenance": [
    {
     "file_id": "1Q_oDw0aMA4QFKDnLxuqJp62P8oPMtO1R",
     "timestamp": 1618255245074
    },
    {
     "file_id": "1FtQ99beHYcDFDywLdaPgFm-KjBeI8PvD",
     "timestamp": 1615884593383
    }
   ]
  },
  "kernelspec": {
   "display_name": "deepunderstandingofdeeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
